# -*- coding: utf-8 -*-
"""What_can_do_ü§ó_Transformers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ca60Y08p5eYOkkM28nY5SWDgURWN0pHH
"""

!pip install datasets evaluate transformers[sentencepiece] gradio

"""## Analyse de Sentiment"""

from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier(
    "It is a pleasure for me to participate in this meetup."  
)   # C'est un plaisir pour moi de participer √† ce meetup.

import pandas as pd

text = "It is a pleasure for me to participate in this meetup."

output = classifier(text)
pd.DataFrame(output)

"""Ce `pipeline` regroupe trois √©tapes : le pr√©traitement, le passage des entr√©es dans le mod√®le et le post-traitement.

<img src='https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg' align='center' width=80%>

On peut faire passer plusieurs phrases:
"""

text = [
        "This course is amazing.",
        "I hate this so much!",
    ]  # ¬´ Ce cours est incroyable. ¬ª,  ¬´ Je d√©teste tellement √ßa ! ¬ª

outputs = classifier(text)
pd.DataFrame(outputs)

"""## Zero-shot classification

Le `zero-shot-classification` est une t√¢che qui consiste √† classer des textes qui n‚Äôont pas √©t√© annot√©s.
"""

from transformers import pipeline

classifier = pipeline("zero-shot-classification")

classifier(
    "This is a course about the Transformers library",
    # C'est un cours sur la biblioth√®que Transformers
    candidate_labels=["education", "politics", "business"],
)

outputs = classifier(
    "This is a course about the Transformers library",
    # C'est un cours sur la biblioth√®que Transformers
    candidate_labels=["education", "politics", "business"],
)

pd.DataFrame(outputs)

"""## Generation de Text

L‚Äôid√©e principale ici est que vous fournissez seulement un extrait de texte qui va √™tre compl√©t√© par du texte g√©n√©r√© automatiquement par le mod√®le.
"""

from transformers import pipeline

generator = pipeline("text-generation")

generator("Linux is the best operating systems", max_length=50) # max_length pour contr√¥ler le nombre caract√®res g√©n√©r√©s

"""## Utiliser n'importe quel mod√®le du Hub dans un pipeline"""

from transformers import pipeline

generator = pipeline("text-generation", model="asi/gpt-fr-cased-base") # pour generer du text en Francais
generator(
    "la vie n'est rien d'autre que le trait d'union du mot peut-√™tre",
    max_length=50
)

"""## Remplacement de mot-masques

L‚Äôargument `top_k` permet de contr√¥ler le nombre de possibilit√©s que vous souhaitez afficher. Notez que dans ce cas, le mod√®le remplace le mot sp√©cial `<mask>`, qui est souvent appel√© un `mot masqu√©`. 
"""

from transformers import pipeline

unmasker = pipeline("fill-mask")
unmasker("This course will teach you all about <mask> models.", top_k=2) # top_k contr√¥ler le nombre de possibilit√©s que vous souhaitez afficher

"""## Reconnaissance d'entit√©s nomm√©es (NER Name Entity Recognition)

La reconnaissance d‚Äôentit√©s nomm√©es ou NER (pour Named Entity Recognition) est une t√¢che o√π le mod√®le doit trouver les parties du texte d‚Äôentr√©e qui correspondent √† des entit√©s telles que des personnes, des lieux ou des organisations.
"""

# from transformers import pipeline

# ner = pipeline("ner", grouped_entities=True)
# ner(
#     "My name is Astou and I have a great enthusiasm for Data."
# )  # Je m'appelle Astou et j'ai un grand enthousiasme pour les donn√©es.

"""## R√©ponse √† des questions

Le pipeline `question-answering` r√©pond √† des questions en utilisant des informations donn√©es en contexte:
"""

# from transformers import pipeline

# question_answerer = pipeline("question-answering")
# question_answerer(
#     question="Where do I work?",  # O√π est-ce que je travaille ?
#     context="My name is Astou and I work at Baamtu Datamation in Dakar",
#     # Je m'appelle Astou et je travaille √† Baamtu √† Dakar.
# )

# reader = pipeline("question-answering")
# question = "Where do I work?"
# text = "I am Astou and I work at Baamtu in Dakar"
# outputs = reader(question=question, context=text)
# pd.DataFrame([outputs])

"""## R√©sum√©

Le r√©sum√© est une t√¢che de r√©duction d‚Äôun texte en un texte plus court, tout en gardant tous (ou presque tous) les aspects importants r√©f√©renc√©s dans le texte.
"""

from transformers import pipeline

summarizer = pipeline("summarization")
summarizer(
    """
    
    L'Am√©rique a chang√© de fa√ßon spectaculaire au cours des derni√®res ann√©es. Non seulement le nombre de 
    dipl√¥m√©s dans les disciplines traditionnelles de l'ing√©nierie telles que le g√©nie m√©canique, civil, 
    l'√©lectricit√©, la chimie et l'a√©ronautique a diminu√©, mais dans la plupart 
    des grandes universit√©s am√©ricaines, les programmes d'√©tudes d'ing√©nierie se concentrent d√©sormais sur 
    et encouragent largement l'√©tude des sciences de l'ing√©nieur. Par cons√©quent, il y a 
    de moins en moins d'offres dans les sujets d'ing√©nierie traitant de l'infrastructure, 
    l'environnement et les questions connexes, et une plus grande concentration sur les sujets de haute 
    technologie, qui soutiennent en grande partie des d√©veloppements scientifiques de plus en plus 
    complexes. Si cette derni√®re est importante, elle ne doit pas se faire au d√©triment
    de l'ing√©nierie plus traditionnelle.

    Les √©conomies en d√©veloppement rapide telles que la Chine et l'Inde, ainsi que d'autres 
    pays industrialis√©s d'Europe et d'Asie, continuent d'encourager et de promouvoir
    l'enseignement de l'ing√©nierie. La Chine et l'Inde, respectivement, dipl√¥ment 
    six et huit fois plus d'ing√©nieurs traditionnels que les √âtats-Unis. 
    Les autres pays industriels maintiennent au minimum leur production, tandis que l'Am√©rique 
    souffre d'une baisse de plus en plus importante du nombre de dipl√¥m√©s en ing√©nierie
    et un manque d'ing√©nieurs bien form√©s.

"""
)

"""## Traduction"""

from transformers import pipeline

translator = pipeline("translation", model="Helsinki-NLP/opus-mt-en-fr")
outputs = translator("GalsenAI is a community of AI enthusiasts.")
outputs[0]['translation_text']

"""## Deployer un mini-application de traduction avec Gradio"""

import gradio as gr

def translate_sentence(input_text):
    """Une fonction qui retourne le texte traduit"""
    for value in translator(input_text)[0].values():
        return value

iface = gr.Interface(fn = translate_sentence, inputs = 'text', outputs = 'text',
                     title = "Traduction EN-FR", 
                     description="Un mini google translate avec huggingface")
                     
iface.launch()

